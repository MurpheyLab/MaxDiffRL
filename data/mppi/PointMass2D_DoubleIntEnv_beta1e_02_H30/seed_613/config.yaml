batch_size: 128
env:
  boundary_distance: 5.0
  done_distance: -1
  noise: true
  start_distance: 1.0
max_frames: 100000
max_steps: 1000
method: mppi
model_activation_fun: ReLU
model_iter: 5
model_layers:
- 128
- 128
model_lr: 0.0005
name_mod: _H30
planner:
  horizon: 30
  lam: 0.5
  samples: 500
reward_activation_fun: ReLU
reward_layers:
- 128
- 128
reward_scale: 1.0
