default:
    method: "maxdiff"
    max_steps: 1000
    max_frames: 1000000
    model_lr: !!float 3e-4
    reward_scale: 1.0
    model_iter: 5
    model_layers: [200,200]
    model_activation_fun: 'ReLU'
    reward_layers: [200,200]
    reward_activation_fun: 'ReLU'
    name_mod: ''
    weights: None
    batch_size: 256
    planner:
        horizon: 5
        samples: 20
        lam: 0.1
        eps: 0.5
        alpha: 5
        explr_dim: None
        weights: None
        window: False

SwimmerEnv_v3:
   max_frames: 1000000
   batch_size: 128
   model_iter: 10
   planner:
       explr_dim: [0,1,5,6]
       weights: [1.,1.,0.05,0.05]
       horizon: 40
       alpha: 50.
       lam: 0.1
       samples: 1000
       window: True
   model_layers: [200,200]
   reward_layers: [200,200]
   name_mod: "_H40_alpha50_singleshot"

AntEnv_v3:
    model_layers: [512,512,512]
    reward_layers: [512,512,512]
    done_layers: None
    batch_size: 256
    name_mod: '_H20_alpha15_singleshot'
    planner:
        explr_dim: [0, 1, 2]
        weights: [1.0, 1.0, 0.005]
        horizon: 20
        alpha: 15
        lam: 0.5
        samples: 1000
        window: False
    task_info:
        include_contacts: False
        task: 'orig'
        desired_speed: None

HalfCheetahEnv_v3:
    max_frames: 1000000
    frame_skip: 1
    planner:
        explr_dim: [0,1,9,10]
        weights: [1.,1.0,0.05,0.05]
        horizon: 10
        alpha: 5
        lam: 0.5
        samples: 1000
        window: False
    model_layers: [200,200]
    reward_layers: [200,200]
    name_mod: "_H10_alpha5_singleshot"
